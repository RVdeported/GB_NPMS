{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1**\n",
    "Импортируйте библиотеки pandas и numpy.\n",
    "Загрузите \"Boston House Prices dataset\" из встроенных наборов данных библиотеки sklearn. Создайте датафреймы X и y из этих данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset[\"data\"],columns = dataset[\"feature_names\"])\n",
    "y = pd.DataFrame(dataset[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разбейте эти датафреймы на тренировочные (X_train, y_train) и тестовые (X_test, y_test) с помощью функции train_test_split так, чтобы размер тестовой выборки составлял 30% от всех данных, при этом аргумент random_state должен быть равен 42."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создайте модель линейной регрессии под названием lr с помощью класса LinearRegression из модуля sklearn.linear_model.\n",
    "Обучите модель на тренировочных данных (используйте все признаки) и сделайте предсказание на тестовых.\n",
    "Вычислите R2 полученных предказаний с помощью r2_score из модуля sklearn.metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7109203586326285"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "lr = LinearRegression(normalize = True)\n",
    "lr.fit(X_train, y_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "R2_lr = r2_score(y_test, y_test_pred)\n",
    "R2_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2**\n",
    "Создайте модель под названием model с помощью RandomForestRegressor из модуля sklearn.ensemble.\n",
    "Сделайте агрумент n_estimators равным 1000, max_depth должен быть равен 12 и random_state сделайте равным 42.\n",
    "\n",
    "Обучите модель на тренировочных данных аналогично тому, как вы обучали модель LinearRegression, но при этом в метод fit вместо датафрейма y_train поставьте y_train.values[:, 0], чтобы получить из датафрейма одномерный массив Numpy, так как для класса \n",
    "RandomForestRegressor в данном методе для аргумента y предпочтительно применение массивов вместо датафрейма.\n",
    "\n",
    "Сделайте предсказание на тестовых данных и посчитайте R2. Сравните с результатом из предыдущего задания.\n",
    "Напишите в комментариях к коду, какая модель в данном случае работает лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear: 71.1%\n",
      "RandomForest: 87.6%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators = 1000,\n",
    "                              max_depth = 12,\n",
    "                              random_state = 42)\n",
    "model.fit(X_train, y_train.values[:, 0])\n",
    "y_test_pred = model.predict(X_test)\n",
    "R2_rf = r2_score(y_test, y_test_pred)\n",
    "print(\"Linear: {:.1f}%\\nRandomForest: {:.1f}%\".format(R2_lr * 100, R2_rf * 100))\n",
    "# По оценке среднеквадтратичной ошибки, модель случайного леса работает ощутимо лучше линейной"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3**\n",
    "Вызовите документацию для класса RandomForestRegressor, найдите информацию об атрибуте feature_importances_.\n",
    "С помощью этого атрибута найдите сумму всех показателей важности, установите, какие два признака показывают наибольшую важность."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5       5.21\n",
       "116    12.04\n",
       "45     10.21\n",
       "16      6.58\n",
       "468    18.13\n",
       "360     7.79\n",
       "3       2.94\n",
       "405    22.98\n",
       "185    13.15\n",
       "60     13.15\n",
       "110    13.00\n",
       "321     6.87\n",
       "265    10.45\n",
       "29     11.98\n",
       "262     5.91\n",
       "478    18.03\n",
       "26     14.81\n",
       "7      19.15\n",
       "492    13.35\n",
       "108    12.27\n",
       "37      8.77\n",
       "157     4.59\n",
       "472    14.36\n",
       "118    15.37\n",
       "114    10.45\n",
       "175     5.33\n",
       "192     2.87\n",
       "272     7.73\n",
       "144    29.29\n",
       "373    34.77\n",
       "       ...  \n",
       "276     6.05\n",
       "443    18.85\n",
       "191     4.69\n",
       "385    30.81\n",
       "293     8.58\n",
       "413    20.08\n",
       "343     7.18\n",
       "257     5.12\n",
       "308     4.54\n",
       "149    21.45\n",
       "130    12.60\n",
       "151    13.28\n",
       "359    12.67\n",
       "99      6.19\n",
       "372     8.88\n",
       "87      8.44\n",
       "458    16.23\n",
       "330     9.09\n",
       "214    29.55\n",
       "466    17.15\n",
       "121    14.27\n",
       "505     7.88\n",
       "20     21.02\n",
       "188     4.56\n",
       "71      9.88\n",
       "106    18.66\n",
       "270    13.00\n",
       "348     5.99\n",
       "435    23.27\n",
       "102    10.63\n",
       "Name: LSTAT, Length: 354, dtype: float64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "rf_model_importances = OrderedDict(zip(X_train.columns, model.feature_importances_))\n",
    "sorted(rf_model_importances.items(), \n",
    "       key = lambda item:item[1], \n",
    "       reverse = True)\n",
    "# наиболее существенными признаками выглядят LSTAT и RM. Судя по описанию признаков, это показатель наличия образования / статуса \n",
    "# проживающих и среднее количество комнат в доме. Вполне ожидаемо, что данные признаки имеют большое влияние на стоимость жилья."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4**\n",
    "В этом задании мы будем работать с датасетом, с которым мы уже знакомы по домашнему заданию по библиотеке Matplotlib, это датасет Credit Card Fraud Detection.Для этого датасета мы будем решать задачу классификации - будем определять,какие из транзакциции по кредитной карте являются мошенническими.Данный датасет сильно несбалансирован (так как случаи мошенничества относительно редки),так что применение метрики accuracy не принесет пользы и не поможет выбрать лучшую модель.Мы будем вычислять AUC, то есть площадь под кривой ROC.\n",
    "\n",
    "Импортируйте из соответствующих модулей RandomForestClassifier, GridSearchCV и train_test_split.\n",
    "Загрузите датасет creditcard.csv и создайте датафрейм df.\n",
    "С помощью метода value_counts с аргументом normalize=True убедитесь в том, что выборка несбалансирована.Используя метод info, проверьте, все ли столбцы содержат числовые данные и нет ли в них пропусков.Примените следующую настройку, чтобы можно было просматривать все столбцы датафрейма:\n",
    "pd.options.display.max_columns = 100.\n",
    "Просмотрите первые 10 строк датафрейма df.\n",
    "Создайте датафрейм X из датафрейма df, исключив столбец Class.\n",
    "Создайте объект Series под названием y из столбца Class.\n",
    "\n",
    "Разбейте X и y на тренировочный и тестовый наборы данных при помощи функции train_test_split, используя аргументы: test_size=0.3, random_state=100, stratify=y.\n",
    "У вас должны получиться объекты X_train, X_test, y_train и y_test.\n",
    "Просмотрите информацию о их форме.\n",
    "Для поиска по сетке параметров задайте такие параметры:\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "'max_features': np.arange(3, 5),\n",
    "'max_depth': np.arange(4, 7)}]\n",
    "Создайте модель GridSearchCV со следующими аргументами:\n",
    "estimator=RandomForestClassifier(random_state=100),\n",
    "param_grid=parameters,\n",
    "scoring='roc_auc',\n",
    "cv=3.\n",
    "Обучите модель на тренировочном наборе данных (может занять несколько минут).\n",
    "Просмотрите параметры лучшей модели с помощью атрибута best_params_.\n",
    "Предскажите вероятности классов с помощью полученнной модели и метода predict_proba.\n",
    "Из полученного результата (массив Numpy) выберите столбец с индексом 1 (вероятность класса 1) и запишите в массив y_pred_proba. Из модуля sklearn.metrics импортируйте метрику roc_auc_score.\n",
    "Вычислите AUC на тестовых данных и сравните с результатом,полученным на тренировочных данных, используя в качестве аргументов массивы y_test и y_pred_proba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv(\"../../Input/creditcard.csv\")) # on a github verssion there is no dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)\n",
    "df.columns\n",
    "X = df[[i for i in df.columns if i != \"Class\"]]\n",
    "y = pd.Series(df[\"Class\"])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 100, \n",
    "                                                    stratify = y)\n",
    "parameters = [{'n_estimators': [10, 15],\n",
    "                'max_features': np.arange(3, 5),\n",
    "                'max_depth': np.arange(4, 7)\n",
    "               }]\n",
    "Grid_model = GridSearchCV(estimator = RandomForestClassifier(random_state = 100),\n",
    "                         param_grid = parameters,\n",
    "                         scoring = 'roc_auc',\n",
    "                         cv = 3)\n",
    "Grid_model.fit(X_train, y_train)\n",
    "Grid_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9462664156037157"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba = Grid_model.predict_proba(X_test)[:,1]\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
